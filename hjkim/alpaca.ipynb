{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KoAlpaca Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 11:24:44.961382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 11:24:45.427593: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-20 11:24:45.545405: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-20 11:24:48.122699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-20 11:24:48.123044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-20 11:24:48.123053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ed058caf774c2ab6b1910852336ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝은 인공지능 분야의 하나로서 연속된 계층을 이룬 신경망 네트워크를 이용합니다. 이 네트워크에서는 데이터를 처리하고 분류하며, 예측 및 분류 작업을 수행합니다. 이러한 네트워크를 만드는 것은 데이터를 대량으로 처리하기 때문에 컴퓨터 성능이 향상됩니다. 예를 들어, 의료 분야에서는 암 진단, 조기 진단, 영상처리 등에 사용됩니다. \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM\n",
    "\n",
    "MODEL = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\", non_blocking=True)\n",
    "model.eval()\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text-generation',\n",
    "    model=model,\n",
    "    tokenizer=MODEL,\n",
    "    device=1\n",
    ")\n",
    "\n",
    "\n",
    "def ask(x, context='', is_input_full=False):\n",
    "    ans = pipe(\n",
    "        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\",\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_full_text=False,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(ans[0]['generated_text'])\n",
    "\n",
    "ask(\"딥러닝이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "면진장치는 지진이나 산사태 등으로 인해 건물이 무너지거나 상하는 것을 방지하기 위해 설치하는 장치입니다. 건물의 땅에 구멍을 내어 건물과 지면 사이에 공기와 물을 주입하여 지면이 떠 있도록 만들어 주는 것으로, 이를 통해 건물이 축대나 벽체 등으로 인해 더 이상 버틸 수 없는 상황이 되더라도, 지반의 침하를 막아 구조체에 대한 안정성을 유지할 수 있도록 합니다. 미국의 경우, 이러한 면진장치가 건물의 수명에 약 100년이라는 긴 시간을 제공한다는 보고도 있습니다. \n"
     ]
    }
   ],
   "source": [
    "question = '면진장치가 뭐야?'\n",
    "ask(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "층간소음은 주거 공간 내에서 발생하는 소음을 의미합니다. 일반적으로는 해당 층의 실내 소음을 측정하여 100dB 이하이면, 층간소음에 영향을 받지 않는다고 판단합니다. 즉, 소음이 발생하는 환경에서도 100dB 정도이면 인간 생활에 방해가 되지 않는 소음 수준으로 여겨집니다. 그러나, 직접적으로 측정된 소음이 이보다 더 작을 경우에는 그 소음을 ‘0dB’로 표시합니다. \n",
      "\n",
      "예를 들어, 소음이 발생하는 환경에서 100dB보다 작은 소음은 0dB로 표시됩니다. 따라서, 인간에게 불쾌감을 주지 않는 소음이 100dB 이하인 것으로 여겨지며, 이는 지하철 소음과 같은 경우에 해당합니다. \n"
     ]
    }
   ],
   "source": [
    "question = '층간소음의 기준이 뭐야?'\n",
    "ask(question)\n",
    "# 층간소음의 기준은 1분을 기준으로 주간에는 40dB, 야간에는 3dB을 넘을 경우에 층간소음으로 분류되며 최고 소음이 주간 55dB, 야간 50dB을 넘을 경우 층간소음 피해가 적용됩니다.\n",
    "# 따라서 아파트나 다중주택 등에서 층간소음을 발생시키지 않도록 주의해야 합니다. 만약 층간소음이 발생한다면 방음 시설 개선을 통해 문제를 해결해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "층간소음은 일반적으로 \"제2종 소음원\"이라고 불리며, 소음도가 특정 환경에서 측정되어 일정 수준 이상인 경우에는 규제 대상으로 취급됩니다. 규제 대상으로 지정되면, 그 기준에 따라 소음도가 측정되며, 일정 수준 이상인 경우에는 벌칙금이나 과태료 등의 처분을 받게 됩니다. \n",
      "\n",
      "일반적으로는 바닥으로부터의 소음의 측정을 기준으로 하고 있으며, 벽이나 천정으로부터의 소음도 따로 측정하는 경우가 있습니다. 소음 측정기는 소음원의 크기와 위치에 따라 소음도를 측정하고, 실내 소음도 측정기는 세대 내에서의 소음도를 측정합니다. \n",
      "\n",
      "또한, 관리사무소나 아파트 단지 내에서는 소음도를 측정하는 것이 의무화되어 있는 경우가 많습니다. 입주자들은 서로 간의 예의와 상호 배려를 위해 소음도를 측정하고, 관리주체에게 신고하는 것이 일반적입니다. \n"
     ]
    }
   ],
   "source": [
    "question = '층간소음의 기준이 뭐야?'\n",
    "ask(question)\n",
    "# 층간소음의 기준은 1분을 기준으로 주간에는 40dB, 야간에는 3dB을 넘을 경우에 층간소음으로 분류되며 최고 소음이 주간 55dB, 야간 50dB을 넘을 경우 층간소음 피해가 적용됩니다.\n",
    "# 따라서 아파트나 다중주택 등에서 층간소음을 발생시키지 않도록 주의해야 합니다. 만약 층간소음이 발생한다면 방음 시설 개선을 통해 문제를 해결해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일반적으로는 아래층의 소음이 더 큰 것이 사실입니다. 하지만 정해진 공식이나 규정은 없습니다. 따라서, 이웃에 대한 예의와 상호 배려가 중요합니다. 층간소음을 해결하기 위해서는 다음과 같은 방법들이 있습니다. \n",
      "\n",
      "1. 일반적으로는 여름과 겨울 모두 동일한 기준으로 측정합니다.\n",
      "2. 그러나 겨울에는 다음과 같은 방법으로 측정합니다.\n",
      "    - 실외운동기구 사용 시: 실내 운동기구 사용 시보다 높은 속도와 활동으로 측정합니다.\n",
      "    - 인터폰 사용 시: 실내가 상대적으로 조용한 경우 인터폰을 사용하는 경우가 많습니다.\n",
      "    - TV 및 음악 감상 시: TV 및 음악을 듣는 경우, 대략 60db 이하의 소음으로 측정합니다.\n",
      "    - 집 전화 통화 중: 집 전화 통화 중에는 50db 이하의 소음으로 측정합니다.\n",
      "3. 측정 시에는 소음기를 사용하여 소음을 측정하거나, 집안을 돌아다니면서 측정할 수 있습니다. 이때, 소음 측정기는 '웨버 스마트 서모스탯'과 같은 측정기를 사용할 수 있습니다.\n",
      "4. 또한, 윗층에 직접 올라가서 측정하는 방법도 있습니다.\n",
      "5. 소음 문제가 심각한 경우에는 국가에서 운영하는 '층간소음 이웃돕기' 앱을 활용하는 것도 좋은 방법입니다.\n",
      "\n",
      "## 출처:\n",
      "- https://cafe.naver.com/usedbookoldbook/34182 \n",
      "- https://cafe.naver.com/usedbookoldbook/34183 \n"
     ]
    }
   ],
   "source": [
    "question = '층간소음의 기준이 뭐야?'\n",
    "ask(question)\n",
    "# 층간소음의 기준은 1분을 기준으로 주간에는 40dB, 야간에는 3dB을 넘을 경우에 층간소음으로 분류되며 최고 소음이 주간 55dB, 야간 50dB을 넘을 경우 층간소음 피해가 적용됩니다.\n",
    "# 따라서 아파트나 다중주택 등에서 층간소음을 발생시키지 않도록 주의해야 합니다. 만약 층간소음이 발생한다면 방음 시설 개선을 통해 문제를 해결해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KoAlpaca Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 17:18:56.491075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 17:18:57.134568: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-23 17:18:57.256017: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-23 17:18:59.550869: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-23 17:18:59.551185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-23 17:18:59.551194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes as bnb\n",
    "import os\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, AdamW, AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, pipeline, AutoModelForQuestionAnswering\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "644it [00:06, 100.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv('train.csv')\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('beomi/KoAlpaca-Polyglot-5.8B',  eos_token='</s>')\n",
    "\n",
    "max_length = 128\n",
    "\n",
    "formatted_data = []\n",
    "for _, row in tqdm(data.iterrows()):\n",
    "  for q_col in ['질문_1', '질문_2']:\n",
    "    for a_col in ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']:\n",
    "      input_text = row[q_col] + tokenizer.eos_token + row[a_col]\n",
    "      input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', truncation=True, max_length=max_length)\n",
    "      formatted_data.append(input_ids)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  1\n"
     ]
    }
   ],
   "source": [
    "# GPU 할당 변경하기\n",
    "GPU_NUM = 1 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드aaa\n",
    "data = pd.read_csv('train_final_0213.csv')\n",
    "# 모델 로드\n",
    "model_id = 'beomi/KoAlpaca-Polyglot-5.8B' # \"LDCC/LDCC-SOLAR-10.7B\"  , beomi/KoAlpaca-llama-1-7b  beomi/KoAlpaca-Polyglot-5.8B beomi/KoAlpaca-Polyglot-12.8B\n",
    "\n",
    "# 인코딩\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_id,  eos_token='</s>')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, eos_token='</s>')\n",
    "\n",
    "input_texts = data['question'] + tokenizer.eos_token + data['answer']\n",
    "formatted_data = []\n",
    "for i in range(len(input_texts)):\n",
    "    input_ids = tokenizer.encode(input_texts[i], return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "    formatted_data.append(input_ids)\n",
    "\n",
    "formatted_data = torch.cat(formatted_data, dim=0) # [6440, 128]\n",
    "\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "# Model : AutoModelForCausalLM AutoModelForQuestionAnswering\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             quantization_config=quant_config,\n",
    "                                             device_map={'':torch.cuda.current_device()},\n",
    "                                            #  device_map={\"\":1},\n",
    "                                            # device_map = 'auto'\n",
    "                                             #torch_dtype=torch.float32,\n",
    "                                             )\n",
    "\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "# LoRA Config\n",
    "config = LoraConfig(\n",
    "    r=8,   # Lora 모델에서 사용되는 LSH (Locality Sensitive Hashing) 테이블의 행 수, LSH 테이블의 해시 버킷의 수\n",
    "    lora_alpha=32,   # Lora 모델에서 사용되는 LSH 테이블의 열 수, LSH 테이블에서 각 해시 버킷에 저장되는 키의 수\n",
    "    target_modules=[\"query_key_value\"],    #\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"  # https://github.com/huggingface/peft/blob/v0.8.2/src/peft/utils/peft_types.py  # CAUSAL_LM\n",
    ")\n",
    "torch.cuda.set_device(device)\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=formatted_data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        # per_device_train_batch_size=2,  # 각 GPU 당 배치 크기\n",
    "        gradient_accumulation_steps=1,  #  그라디언트 누적 단계 수 지정. 1보다 크면 여러 배치를 합쳐 그라디언트 계산 후 가중치 업데이트\n",
    "        max_steps=500,\n",
    "        learning_rate=1e-4,\n",
    "        fp16=True,   # 모델 매개변수와 그라디언트 16비트 부동 소수점으로 저장하여 학습 가속화\n",
    "        logging_steps=10,   # 로그 출력 시 간격 지정\n",
    "        output_dir=\"outputs\",   # 학습된 모델과 로그 저장할 디렉토리\n",
    "        optim=\"paged_adamw_8bit\",   # 사용할 옵티마이저\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),   # 데이터 배치 처리기\n",
    ")\n",
    "\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning된 모델 저장\n",
    "today = datetime.now().strftime(\"%m%d\")\n",
    "memo = 'base'\n",
    "new_model = f'KoAlpaca_{today}_{memo}'\n",
    "\n",
    "tuning_model.save_pretrained(f\"./{new_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe2d7771ff84158b89540ca7beb0fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForQuestionAnswering were not initialized from the model checkpoint at beomi/KoAlpaca-Polyglot-5.8B and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only automatically infer lengths for datasets whose items are dictionaries with an 'input_ids' key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 63\u001b[0m\n\u001b[1;32m     53\u001b[0m tuning_model \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     54\u001b[0m     model\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[1;32m     55\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mmy_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     args\u001b[38;5;241m=\u001b[39mtrain_params\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mtuning_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1551\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 1553\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;66;03m# Setting up training control variables:\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;66;03m# number of training epochs: num_train_epochs\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# number of training steps per epoch: num_update_steps_per_epoch\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# total number of training steps to execute: max_steps\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m total_train_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mworld_size\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:850\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m dataloader_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size,\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollate_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_collator,\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpin_memory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_pin_memory,\n\u001b[1;32m    847\u001b[0m }\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterableDataset):\n\u001b[0;32m--> 850\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_train_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_drop_last\n\u001b[1;32m    852\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_init_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed_worker\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:813\u001b[0m, in \u001b[0;36mTrainer._get_train_sampler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m         lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    812\u001b[0m     model_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLengthGroupedSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RandomSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer_pt_utils.py:574\u001b[0m, in \u001b[0;36mLengthGroupedSampler.__init__\u001b[0;34m(self, batch_size, dataset, lengths, model_input_name, generator)\u001b[0m\n\u001b[1;32m    569\u001b[0m     model_input_name \u001b[38;5;241m=\u001b[39m model_input_name \u001b[38;5;28;01mif\u001b[39;00m model_input_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    571\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m], BatchEncoding))\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m model_input_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    573\u001b[0m     ):\n\u001b[0;32m--> 574\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only automatically infer lengths for datasets whose items are dictionaries with an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_input_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         )\n\u001b[1;32m    578\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(feature[model_input_name]) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lengths, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "\u001b[0;31mValueError\u001b[0m: Can only automatically infer lengths for datasets whose items are dictionaries with an 'input_ids' key."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "# Tensor를 TensorDataset으로 변환\n",
    "my_dataset = TensorDataset(formatted_data)\n",
    "\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "# Model\n",
    "base_model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 1}\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1\n",
    "\n",
    "# LoRA Config\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"QUESTION_ANS\"\n",
    ")\n",
    "\n",
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"./results_modified\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "tuning_model = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=my_dataset,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "tuning_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.config.use_cache = True  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 09:13:23.125182: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 09:13:23.504005: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-23 09:13:23.594044: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-23 09:13:25.148530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-23 09:13:25.153376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-23 09:13:25.153387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes as bnb\n",
    "import os\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, AdamW, AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, pipeline\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54276cb7fd93467fb70b7e7213a79013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "new_model = 'KoAlpaca_0219_base'\n",
    "# model_2 = AutoModelForCausalLM.from_pretrained(f'./{new_model}')\n",
    "model_2 = AutoModelForCausalLM.from_pretrained(\n",
    "    f'./{new_model}',\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map={\"\":1},\n",
    "    # device_map='auto'\n",
    ")\n",
    "# .to(device=f\"cuda\", non_blocking=True)\n",
    "\n",
    "model_id = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "\n",
    "# 인코딩\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_id,  eos_token='</s>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x):\n",
    "    gened = model_2.generate(\n",
    "        **tokenizer(\n",
    "            f\"### 질문: {x}\\n\\n### 답변:\",\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda'),\n",
    "        max_new_tokens=256,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    # print(tokenizer.decode(gened[0]))\n",
    "    return tokenizer.decode(gened[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    'text-generation',\n",
    "    model=model_2,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "def ask(x, context='', is_input_full=False):\n",
    "    ans = pipe(\n",
    "        # x,\n",
    "        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\",\n",
    "        do_sample=True,    # 확률적 샘플링을 사용하여 다음 토큰을 선택\n",
    "        max_new_tokens=256,   #  생성될 최대 토큰 수를 정의\n",
    "        temperature=0.1,  # 샘플링 시에 사용되는 온도(temperature), 높을수록 다양한 텍스트 생성\n",
    "        top_p=0.1,    # 모델이 고려할 토큰의 확률 분포. 누적 확률이 주어진 값 이상이 되는 토큰만을 고려\n",
    "        return_full_text=False,  # 전체 텍스트를 반환할지 여부. False = 특정 길이 이상 텍스트 반환 x\n",
    "        eos_token_id=2,   # 종료 토큰의 ID\n",
    "    )\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '어떤 상황에 개별 공간이 더 적합한지, 어떤 상황에 오픈 플랜 공간이 더 적합한지 알려주세요. 그리고 합지벽지의 어떤 단점이 있나요?'\n",
    "answer = ask(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 1/130 [00:22<47:53, 22.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 2/130 [00:41<43:19, 20.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 3/130 [00:47<28:57, 13.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 4/130 [00:59<27:26, 13.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 5/130 [01:06<23:14, 11.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 6/130 [01:16<21:41, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 7/130 [01:25<21:00, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 8/130 [01:38<22:34, 11.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 9/130 [01:48<21:42, 10.76s/it]/home/hjkim/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 10/130 [01:56<19:41,  9.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 11/130 [02:08<20:49, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 12/130 [02:13<17:14,  8.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 13/130 [02:22<17:31,  8.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 14/130 [02:31<17:08,  8.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 15/130 [02:49<22:14, 11.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 16/130 [02:56<19:38, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 17/130 [03:08<20:14, 10.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 18/130 [03:24<22:53, 12.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▍        | 19/130 [03:55<33:08, 17.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 20/130 [04:06<29:04, 15.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 21/130 [04:39<38:05, 20.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 22/130 [04:47<30:43, 17.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 23/130 [05:01<28:47, 16.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 24/130 [05:23<31:44, 17.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 25/130 [05:35<28:32, 16.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 26/130 [05:55<29:48, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 27/130 [06:09<28:10, 16.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 28/130 [06:18<23:58, 14.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 29/130 [06:26<20:40, 12.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 30/130 [06:35<18:48, 11.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 31/130 [07:01<25:46, 15.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▍       | 32/130 [07:07<20:48, 12.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 33/130 [07:12<16:48, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 34/130 [07:20<15:47,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 35/130 [07:31<16:03, 10.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 36/130 [07:47<18:29, 11.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 37/130 [07:54<16:11, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 38/130 [08:17<21:47, 14.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 39/130 [08:27<19:37, 12.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 40/130 [08:39<19:04, 12.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 41/130 [08:51<18:35, 12.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 42/130 [09:03<17:55, 12.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 43/130 [09:18<18:58, 13.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 44/130 [09:30<18:23, 12.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▍      | 45/130 [09:45<19:07, 13.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 46/130 [09:57<18:22, 13.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 47/130 [10:08<16:58, 12.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 48/130 [10:19<16:08, 11.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 49/130 [10:32<16:32, 12.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 50/130 [10:44<16:18, 12.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 51/130 [10:52<14:16, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 52/130 [11:01<13:28, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 53/130 [11:17<15:29, 12.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 54/130 [11:42<20:08, 15.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 55/130 [11:52<17:49, 14.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 56/130 [12:03<16:28, 13.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 57/130 [12:19<17:03, 14.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▍     | 58/130 [13:01<26:56, 22.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 59/130 [13:13<22:59, 19.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 60/130 [13:25<19:48, 16.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 61/130 [13:38<18:18, 15.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 62/130 [13:47<15:46, 13.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 63/130 [13:51<12:08, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 64/130 [14:09<14:17, 13.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 65/130 [14:23<14:12, 13.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 66/130 [14:37<14:15, 13.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 67/130 [14:50<14:01, 13.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 68/130 [14:54<11:03, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 69/130 [15:09<12:10, 11.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 70/130 [15:15<10:11, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 71/130 [15:26<10:05, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▌    | 72/130 [15:39<10:40, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 73/130 [15:51<10:54, 11.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 74/130 [16:12<13:18, 14.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 75/130 [16:21<11:45, 12.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 76/130 [16:38<12:41, 14.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 77/130 [16:42<09:46, 11.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|██████    | 78/130 [16:53<09:30, 10.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 79/130 [17:03<09:02, 10.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 80/130 [17:17<09:36, 11.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 81/130 [17:42<12:44, 15.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 82/130 [17:56<12:03, 15.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 83/130 [18:12<12:06, 15.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 84/130 [18:24<11:04, 14.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▌   | 85/130 [18:43<11:50, 15.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 86/130 [19:01<12:08, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 87/130 [19:09<09:53, 13.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 88/130 [19:24<09:52, 14.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 89/130 [19:41<10:15, 15.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 90/130 [19:57<10:22, 15.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|███████   | 91/130 [20:19<11:14, 17.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 92/130 [20:26<08:59, 14.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 93/130 [20:34<07:36, 12.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 94/130 [20:42<06:43, 11.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 95/130 [20:49<05:43,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 96/130 [20:57<05:16,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 97/130 [21:08<05:20,  9.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▌  | 98/130 [21:17<05:04,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 99/130 [21:24<04:32,  8.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 100/130 [21:34<04:35,  9.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 101/130 [21:44<04:29,  9.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 102/130 [21:57<04:51, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 103/130 [22:08<04:49, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████  | 104/130 [22:21<04:58, 11.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 105/130 [22:33<04:51, 11.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 106/130 [22:49<05:06, 12.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 107/130 [23:00<04:44, 12.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 108/130 [23:20<05:24, 14.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 109/130 [23:31<04:46, 13.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 110/130 [23:42<04:12, 12.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▌ | 111/130 [23:53<03:51, 12.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 112/130 [24:05<03:38, 12.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 113/130 [24:29<04:24, 15.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 114/130 [24:40<03:51, 14.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 115/130 [24:52<03:24, 13.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 116/130 [25:15<03:50, 16.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|█████████ | 117/130 [25:35<03:47, 17.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 118/130 [25:47<03:10, 15.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 119/130 [25:58<02:38, 14.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 120/130 [26:07<02:06, 12.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 121/130 [26:24<02:07, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 122/130 [26:38<01:51, 13.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 123/130 [26:52<01:37, 13.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▌| 124/130 [26:57<01:08, 11.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 125/130 [27:11<01:01, 12.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 126/130 [27:27<00:53, 13.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 127/130 [27:36<00:35, 12.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 128/130 [27:43<00:20, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 129/130 [28:01<00:12, 12.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 130/130 [28:07<00:00, 12.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 로드a\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    question = test_data.loc[i, '질문']\n",
    "    # answer = gen(question)\n",
    "    answer = ask(question)\n",
    "    test_data.loc[i, '답변'] = answer[0]['generated_text']\n",
    "    # test_data.loc[i, '답변'] = answer.split('### 답변:')[1]\n",
    "test_data.to_csv(\"answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = pd.read_excel('dacon_llm_answer.xlsx')\n",
    "test_data_2 = test_data_2.merge(test_data[['id', '답변']], on ='id')\n",
    "test_data_2.to_csv(\"answer_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/hjkim/.local/lib/python3.8/site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/hjkim/.local/lib/python3.8/site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.10.1)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 127.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 93.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /home/hjkim/.local/lib/python3.8/site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from rouge) (1.14.0)\n",
      "Requirement already satisfied: filelock in /home/hjkim/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hjkim/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/hjkim/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hjkim/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/hjkim/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (2019.11.28)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hjkim/.local/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hjkim/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.11.0->sentence-transformers) (12.3.101)\n",
      "Installing collected packages: nltk, sentencepiece, sentence-transformers, rouge\n",
      "Successfully installed nltk-3.8.1 rouge-1.0.1 sentence-transformers-2.3.1 sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c691f95ed6483c9040faeefd2d8533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fef5adb207949c5ad11b3ee9bbdf06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa6b62bddd7498bab7f3de9927345a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96224704df8a414e8aad7f97d98351c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d894e531734cc4ac9b7dc44d0b794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/556 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a3b15cb12f48a5807eec9ce262c8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3576bb7cfbb4d308e508e245529e16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/452 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254caf07715b4c35b9b8a97a04190c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c0371e2abe4fe98eef71374860002e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7041fce5f8fa45daa4392695417fbd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d10d3972e7f4ddcb4b20ceb2c5daf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46021879bfa54cd287842a83c4a22210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4c44c97e084a779d1b75c284abaf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 샘플에 대한 Cosine Similarity 산식\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>질문</th>\n",
       "      <th>모범 답안</th>\n",
       "      <th>GPT 답변</th>\n",
       "      <th>TRAIN ID</th>\n",
       "      <th>추가 답안</th>\n",
       "      <th>답변</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_006</td>\n",
       "      <td>어떤 상황에 개별 공간이 더 적합한지, 어떤 상황에 오픈 플랜 공간이 더 적합한지 ...</td>\n",
       "      <td>개인 성향과 생활 방식에 따라 적합한 공간이 다를 수 있지만, 개별 공간은 개인의 ...</td>\n",
       "      <td>개별 공간은 프라이버시를 제공하고 조용한 환경을 유지할 수 있으며, 오픈 플랜은 연...</td>\n",
       "      <td>TRAIN_062\\nTRAIN_067</td>\n",
       "      <td>합지벽지는 화재 발생시 유해물질이 발생할 수 있다는 단점이 있다.</td>\n",
       "      <td>개별 공간의 크기와 디자인에 따라 적합한 공간이 달라질 수 있습니다. 또한, 합지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_009</td>\n",
       "      <td>고층 건물을 건축할 때 철골구조가 주로 선택되는 이유는 무엇인가요?</td>\n",
       "      <td>철골구조는 건물의 외벽에 그다지 하중이 걸리지 않기 때문에 고층 건물의 건축이 가능...</td>\n",
       "      <td>고층 건물을 건축할 때 철골구조가 주로 선택되는 이유는 건물의 외벽에 하중이 적게 ...</td>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>철골구조는 고층 건물을 건축할 때 주로 선택되는 이유 중 하나입니다. 철골구조는 건...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_017</td>\n",
       "      <td>어떤 환경 요인이 몰딩 수정을 유발할 수 있는가요? 그리고 반점이 생긴지 1년 이내...</td>\n",
       "      <td>고습도 환경에서 몰딩 소재가 팽창하거나 수축하여 변형될 수 있는데, 이는 습기가 몰...</td>\n",
       "      <td>고습도 환경에서 몰딩 소재가 팽창하거나 수축하여 변형될 수 있습니다. \\n반점이 생...</td>\n",
       "      <td>TRAIN_354\\nTRAIN_346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>몰딩 수정을 유발하는 환경 요인에는 온도, 습도, 환기, 그리고 실내 습도가 있습...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_022</td>\n",
       "      <td>타일 바닥에서 파손된 타일을 교체하는 과정에 어떤 단계가 포함되나요? 또한, 겨울에...</td>\n",
       "      <td>파손된 타일을 교체하는 방법은 다음과 같습니다. 1. 먼저 파손된 타일을 완전히 제...</td>\n",
       "      <td>타일 바닥에서 파손된 타일을 교체하는 과정은 다음과 같습니다: 손상된 타일을 제거하...</td>\n",
       "      <td>TRAIN_415\\nTRAIN_428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>타일 바닥에서 파손된 타일을 교체하는 과정에는 다음과 같은 단계가 포함됩니다. 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_027</td>\n",
       "      <td>평지붕의 단점은 무엇인가요? 그리고 실크벽지의 교체 주기는 얼마나인가요?</td>\n",
       "      <td>평지붕의 단점은 경사지붕보다 에너지 손실이 크고 단열, 방수를 위한 시공비가 많이들...</td>\n",
       "      <td>평지붕의 단점은 에너지 손실과 누수 위험이 크며 수명이 짧은 편입니다. \\n실크벽지...</td>\n",
       "      <td>TRAIN_061\\nTRAIN_066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>평지붕의 단점은 여러 가지가 있습니다. 먼저, 평지붕은 지붕재의 무게와 설치 비용이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                 질문   \n",
       "0  TEST_006  어떤 상황에 개별 공간이 더 적합한지, 어떤 상황에 오픈 플랜 공간이 더 적합한지 ...  \\\n",
       "1  TEST_009              고층 건물을 건축할 때 철골구조가 주로 선택되는 이유는 무엇인가요?   \n",
       "2  TEST_017  어떤 환경 요인이 몰딩 수정을 유발할 수 있는가요? 그리고 반점이 생긴지 1년 이내...   \n",
       "3  TEST_022  타일 바닥에서 파손된 타일을 교체하는 과정에 어떤 단계가 포함되나요? 또한, 겨울에...   \n",
       "4  TEST_027           평지붕의 단점은 무엇인가요? 그리고 실크벽지의 교체 주기는 얼마나인가요?   \n",
       "\n",
       "                                               모범 답안   \n",
       "0  개인 성향과 생활 방식에 따라 적합한 공간이 다를 수 있지만, 개별 공간은 개인의 ...  \\\n",
       "1  철골구조는 건물의 외벽에 그다지 하중이 걸리지 않기 때문에 고층 건물의 건축이 가능...   \n",
       "2  고습도 환경에서 몰딩 소재가 팽창하거나 수축하여 변형될 수 있는데, 이는 습기가 몰...   \n",
       "3  파손된 타일을 교체하는 방법은 다음과 같습니다. 1. 먼저 파손된 타일을 완전히 제...   \n",
       "4  평지붕의 단점은 경사지붕보다 에너지 손실이 크고 단열, 방수를 위한 시공비가 많이들...   \n",
       "\n",
       "                                              GPT 답변              TRAIN ID   \n",
       "0  개별 공간은 프라이버시를 제공하고 조용한 환경을 유지할 수 있으며, 오픈 플랜은 연...  TRAIN_062\\nTRAIN_067  \\\n",
       "1  고층 건물을 건축할 때 철골구조가 주로 선택되는 이유는 건물의 외벽에 하중이 적게 ...             TRAIN_002   \n",
       "2  고습도 환경에서 몰딩 소재가 팽창하거나 수축하여 변형될 수 있습니다. \\n반점이 생...  TRAIN_354\\nTRAIN_346   \n",
       "3  타일 바닥에서 파손된 타일을 교체하는 과정은 다음과 같습니다: 손상된 타일을 제거하...  TRAIN_415\\nTRAIN_428   \n",
       "4  평지붕의 단점은 에너지 손실과 누수 위험이 크며 수명이 짧은 편입니다. \\n실크벽지...  TRAIN_061\\nTRAIN_066   \n",
       "\n",
       "                                   추가 답안   \n",
       "0  합지벽지는 화재 발생시 유해물질이 발생할 수 있다는 단점이 있다.   \\\n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "\n",
       "                                                  답변  \n",
       "0   개별 공간의 크기와 디자인에 따라 적합한 공간이 달라질 수 있습니다. 또한, 합지...  \n",
       "1  철골구조는 고층 건물을 건축할 때 주로 선택되는 이유 중 하나입니다. 철골구조는 건...  \n",
       "2   몰딩 수정을 유발하는 환경 요인에는 온도, 습도, 환기, 그리고 실내 습도가 있습...  \n",
       "3   타일 바닥에서 파손된 타일을 교체하는 과정에는 다음과 같은 단계가 포함됩니다. 1...  \n",
       "4  평지붕의 단점은 여러 가지가 있습니다. 먼저, 평지붕은 지붕재의 무게와 설치 비용이...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 :   개별 공간의 크기와 디자인에 따라 적합한 공간이 달라질 수 있습니다. 또한, 합지벽지의 단점으로는 건조 시간이 오래 걸리며, 유지 보수가 어렵다는 점이 있습니다. 반면에, 오픈 플랜 공간은 개별 공간의 크기와 디자인에 따라 적합한 공간을 만들 수 있습니다. 또한, 합지벽지보다 저렴하고 친환경적인 재료로 만들어져 있다는 장점이 있습니다.\n",
      "정답 :  개별 공간은 프라이버시를 제공하고 조용한 환경을 유지할 수 있으며, 오픈 플랜은 연결감을 높이고 활동적인 라이프스타일에 더 적합합니다. \n",
      "합지벽지의 단점은 수명이 짧고 내구성이 약하며 오염이 생기면 청소가 어렵고 변색될 수 있다는 점입니다.\n",
      "Cosine Similarity Score :  0.6214631\n",
      "--------------------\n",
      "예측 :  철골구조는 고층 건물을 건축할 때 주로 선택되는 이유 중 하나입니다. 철골구조는 건물의 무게를 지탱하는 데 적합하며, 고층 건물의 안정성을 높일 수 있습니다. 또한, 철골구조는 고층 건물의 내구성을 높일 수 있으며, 고층 건물의 견고성을 높일 수 있습니다.\n",
      "정답 :  고층 건물을 건축할 때 철골구조가 주로 선택되는 이유는 건물의 외벽에 하중이 적게 걸리기 때문에 고층 건물을 건축할 수 있기 때문입니다.\n",
      "Cosine Similarity Score :  0.76998866\n",
      "--------------------\n",
      "예측 :   몰딩 수정을 유발하는 환경 요인에는 온도, 습도, 환기, 그리고 실내 습도가 있습니다. 이러한 환경 요인은 몰딩의 재질, 두께, 마감재의 종류에 따라 달라질 수 있습니다. 따라서, 몰딩 수정을 유발하는 환경 요인을 고려하여 적절한 보수작업을 수행해야 합니다. 반점이 생긴지 1년 이내인 경우, 해당 부분에 대한 보수작업을 진행해야 합니다. 만약 반점이 생긴지 1년 이상이 지났다면, 해당 부분에 대한 추가적인 보수작업이 필요합니다. 이러한 환경 요인을 고려하여 보수작업을 수행하는 것이 중요합니다.\n",
      "정답 :  고습도 환경에서 몰딩 소재가 팽창하거나 수축하여 변형될 수 있습니다. \n",
      "반점이 생긴지 1년 이내라면 벽지 속지 내부에 아세톤을 사용하여 반점을 증발시키는 것이 가능합니다. 그러나 1년 이상된 경우에는 벽지를 재시공하는 것이 필요할 수 있습니다.\n",
      "Cosine Similarity Score :  0.63270825\n",
      "--------------------\n",
      "예측 :   타일 바닥에서 파손된 타일을 교체하는 과정에는 다음과 같은 단계가 포함됩니다. 1. 타일을 떼어내고, 바닥에 있는 틈새나 파손된 부분을 제거합니다. 2. 타일을 제거한 후, 바닥에 있는 틈새나 파손 부분을 깨끗하게 닦아줍니다. 3. 타일을 다시 붙이기 위해 필요한 접착제를 사용하여 바닥에 붙이고, 다시 바닥과 타일을 접착제로 고정합니다. 4. 마지막으로, 타일을 바닥에 다시 붙이고, 바닥과 타일을 접착제로 고정합니다.\n",
      "정답 :  타일 바닥에서 파손된 타일을 교체하는 과정은 다음과 같습니다: 손상된 타일을 제거하고 깨끗한 표면을 만든 후 새 타일을 설치하고 고정합니다. \n",
      "겨울에 도배를 할 때에는 온도를 일정하게 유지하고, 과열을 피하며, 환기를 조절하여 도배지가 고르게 건조되도록 해야 합니다.\n",
      "Cosine Similarity Score :  0.7498884\n",
      "--------------------\n",
      "예측 :  평지붕의 단점은 여러 가지가 있습니다. 먼저, 평지붕은 지붕재의 무게와 설치 비용이 많이 들 수 있습니다. 또한, 지붕재의 부식이나 파손이 발생할 가능성이 높아집니다. 또한, 평지붕은 습기와 바람에 취약하며, 이로 인해 지붕재의 수명이 짧아질 수 있습니다.\n",
      "정답 :  평지붕의 단점은 에너지 손실과 누수 위험이 크며 수명이 짧은 편입니다. \n",
      "실크벽지의 교체 주기는 일반적으로 5~7년입니다.\n",
      "Cosine Similarity Score :  0.6022292\n",
      "--------------------\n",
      "예측 :   프리케스트 콘크리트 구조는 콘크리트를 여러 개의 블록으로 나누어 쌓아올린 구조를 말합니다. 이 구조는 건물의 구조적 안정성을 높이고, 시공이 용이하며, 내구성이 높아 고층 건물에 적합합니다. 또한, 프리케스트 콘크리트 구조는 지진이나 지진에 따른 충격을 흡수할 수 있는 장점이 있습니다.\n",
      "정답 :  프리케스트 콘크리트 구조는 건축물의 콘크리트 부재를 공장에서 미리 제작한 후 현장에서 조립하는 방식으로, 원가 절감과 품질 확보의 장점을 가지고 있습니다. \n",
      "조적식 구조는 벽돌이나 콘크리트 블록을 모르타르로 쌓는 방식으로, 내구성과 경제성을 갖추고 있지만 수평 외력에 상대적으로 취약할 수 있습니다.\n",
      "Cosine Similarity Score :  0.71277547\n",
      "--------------------\n",
      "예측 :   KMEW 세라믹 지붕재의 단점은 내구성이 낮고, 시공이 어렵다는 것입니다. 또한, 시공비가 비싸고, 유지보수 비용이 높다는 것도 단점으로 꼽힙니다.\n",
      "정답 :  KMEW 세라믹 지붕재의 단점은 가격이 높고 무게가 무거워서 추가적인 강화와 지지대가 필요할 수 있습니다. \n",
      "세라믹 타일의 경우에는 온도 변화에 민감하고 내장용으로만 사용해야 하며, 경도가 낮아 충격과 마모에 취약합니다. 또한, 표면이 미끄러울 수 있어서 삼림 지역이나 욕실 등에서의 사용에는 적합하지 않을 수 있습니다.\n",
      "Cosine Similarity Score :  0.77615047\n",
      "--------------------\n",
      "예측 :   바닥재가 남으면 다음과 같은 방법으로 처리할 수 있습니다. 먼저, 바닥재를 제거하기 위해 바닥재를 제거하는 도구를 사용하거나, 바닥재를 제거하는 전문 업체에 의뢰할 수 있습니다. 또한, 바닥재를 제거한 후에는 바닥재가 더 이상 사용되지 않도록 청소하고, 바닥재를 제거한 후에는 바닥재가 더 이상 사용되지 않도록 청소해야 합니다. 마지막으로, 바닥재가 제거된 후에는 바닥재가 더 이상 사용되지 않도록 청소하고, 바닥재가 더 이상 사용되지 않을 때까지 청소를 계속해야 합니다.\n",
      "정답 :  바닥재가 남으면 지역의 구청이나 주민센터에 문의하여 특수 규격 봉투를 이용한 배출 방법을 확인하고, 5톤 이상의 양은 전문 업체를 통해 처리하는 것이 좋습니다. \n",
      "장판이 남을 경우에는 구청이나 주민센터에서 생활폐기물 스티커를 구매하여 해당 기관이 정한 방법에 따라 배출하는 것이 필요합니다.\n",
      "Cosine Similarity Score :  0.45517358\n",
      "--------------------\n",
      "예측 :   원목마루는 주로 나무로 만들어지며, 나무의 종류에 따라 다양한 색상과 디자인이 있습니다. 또한, 원목마루는 일반적으로 친환경적이며, 자연스러운 느낌을 주는 장점이 있습니다. 반면, 롱브릭타일은 주로 타일로 만들어지며, 다양한 색상과 디자인으로 구성되어 있습니다. 또한, 롱브릭타일은 일반적으로 방수 및 방수 기능이 뛰어나고, 청소가 쉬우며, 내구성이 높다는 장점이 있습니다.\n",
      "정답 :  원목마루는 열전도율이 높아 난방 효율이 좋고, 심미성과 쿠션감, 촉감이 우수하지만, 습기에 취약하며 온돌에 시공할 경우 갈라질 위험이 있습니다. \n",
      "모노롱브릭타일은 노출 콘크리트와 유사한 분위기를 연출할 수 있으나, 단열과 습도조절 효과가 부족하고, 벽돌에 비해 상대적으로 얇은 두께로 쉽게 깨질 수 있습니다.\n",
      "Cosine Similarity Score :  0.5048926\n",
      "--------------------\n",
      "예측 :   컬러매치를 효과적으로 활용하기 위해서는 공간의 컬러와 조화를 이루는 소품을 활용하는 것이 중요합니다. 컬러와 소품을 조화롭게 활용하면 공간을 더욱 깔끔하고 매력적으로 만들 수 있습니다. 또한, 컬러를 활용할 때에는 공간의 분위기와 조화를 이루는 것이 중요합니다. 예를 들어, 화이트 컬러와 파스텔 컬러를 활용하여 공간을 밝고 깔끔하게 만들 수 있습니다. 또한, 공간을 확장시키기 위해서는 컬러와 소품을 활용하여 공간을 확장시키는 것이 효과적입니다. 컬러와 소품을 활용하여 공간을 확장시키면 공간을 더욱 넓게 보이게 할 수 있습니다.\n",
      "정답 :  컬러매치를 위해 대비 컬러와 조화 컬러를 조합하고, 컬러 선택 시 공간의 크기와 목적, 채광, 가구의 색상과 재질을 고려해야 합니다.\n",
      "\n",
      "복도나 협소한 공간을 확장하기 위해 큰 거울을 사용하거나, 밝은 컬러의 벽지 및 가구, 슬림한 디자인의 가구를 선택하는 것이 효과적입니다.\n",
      "Cosine Similarity Score :  0.6105368\n",
      "--------------------\n",
      "예측 :   방청페인트를 시공하는 방법은 다음과 같습니다. 먼저, 사용하는 도료를 선택하여 시공할 공간의 크기를 측정한 후, 해당 공간에 맞는 두께로 도료를 시공합니다. 그리고 도료를 시공한 후, 벽면을 깨끗하게 닦아내고, 도료가 완전히 건조될 때까지 건조시키는 과정을 거칩니다. 마지막으로, 도료를 제거하기 위해 물을 뿌리고, 건조시키는 과정을 반복합니다.\n",
      "정답 :  방청페인트의 시공단계는 피도면 정리, 방청도료 도장, 상도작업입니다. \n",
      "통기구는 배수관에서 나는 악취를 외부로 배출하고 배수도의 흐름을 원활하게 하기 위해 설치됩니다.\n",
      "Cosine Similarity Score :  0.46218902\n",
      "--------------------\n",
      "예측 :   원목마루의 단점으로는 청소가 어렵고, 유지 보수 비용이 많이 들며, 습기와 열에 취약하다는 점이 있습니다. 또한, 원목마루는 습기와 열에 취약하기 때문에, 습기와 열을 차단하는 것이 중요합니다. 도배지가 남으면 재활용이 불가능하므로, 도배지를 재활용하는 것이 어렵습니다.\n",
      "정답 :  원목마루의 단점은 비용이 높고, 열전도율이 낮아 열원에 취약하며, 습기에 민감하다는 것입니다.\n",
      "도배지는 폐기물 스티커를 부착하여 처리할 수 있습니다.\n",
      "Cosine Similarity Score :  0.56638396\n",
      "--------------------\n",
      "예측 :   강마루 바닥재는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루는 강마루로 만들어진 바닥재로, 강마루\n",
      "정답 :  강마루의 장점은 표면 내구성이 좋고 다양한 디자인으로 제공되며 유지보수가 쉽고, 열전도율이 높아 난방 효과가 우수하며 소음 발생이 적다는 것입니다.\n",
      "Cosine Similarity Score :  0.1701065\n",
      "--------------------\n",
      "예측 :   도배풀을 제거하는 데 가장 효과적인 도구는 도배풀 제거용 스프레이입니다. 이 스프레이는 도배풀을 제거하는 데 사용되며, 도배풀의 표면을 깨끗하게 만들어주는 효과가 있습니다. 또한, 도배풀을 제거한 후에는 도배풀을 제거한 부분을 깨끗하게 닦아내고, 도배풀을 제거한 후에는 도배지를 깨끗하게 닦아내는 것이 좋습니다.\n",
      "정답 :  도배풀을 제거하는 데는 걸레로 살살 닦는 것이 가장 효과적이며, 도배풀이 남으면 도배풀 제거제를 사용해야 합니다. \n",
      "\n",
      "옥상 방수용 탄성 에멀전 페인트의 장점은 건조 후 이음매 없는 도막이 뛰어난 내수성을 가지며, 충격이나 수축과 팽창에도 탄성과 인장강도를 보유하여 손상 방지와 내구성을 갖추며, 장기간의 옥외폭로 조건에서도 우수한 성능을 발휘한다는 것입니다.\n",
      "Cosine Similarity Score :  0.6798131\n",
      "--------------------\n",
      "예측 :   라돈을 측정하는 가장 적합한 지점은 건물의 내부와 외부 모두에서 발생할 수 있습니다. 건물 내부에서 발생하는 라돈은 주로 지하실에서 발견됩니다. 또한, 외부에서 발생하는 라돈은 실외, 실외, 실외, 실내 등 다양한 공간에서 발견될 수 있습니다. 이러한 공간들은 건물 내부와 외부의 온도 차이, 실내의 습도, 환기 등의 요인에 따라 발생할 수 있습니다.\n",
      "정답 :  라돈을 측정하는 가장 적합한 지점은 공동주택의 최저층이며, 총 세대수에 따라 3세대에서 12세대까지 측정합니다. \n",
      "MSDS(Material Safety Data Sheet)는 화학 물질의 잠재적 위험 정보와 안전한 취급, 보관, 폐기에 대한 지침을 담고 있습니다.\n",
      "Cosine Similarity Score :  0.42195183\n",
      "--------------------\n",
      "예측 :  새집증후군을 해결하기 위한 방법으로는 다양한 방법이 있습니다. 먼저, 환기를 통해 실내 공기질을 개선하는 것이 중요합니다. 또한, 청소를 통해 집안을 깨끗하게 유지하고, 친환경적인 가구와 가전제품을 선택하여 사용하는 것도 좋은 방법입니다. 또한, 공기 정화 및 습도 조절을 위한 식물을 활용하는 것도 좋은 방법입니다.\n",
      "정답 :  새집증후군 해결 방법은 다음과 같습니다. 1.천연 소재 사용 및 포름알데히드 처리를 하지 않은 자재 선택 2.창문을 열어 자연 환기 유도 3.이사 전에 30도 이상으로 실내 난방 유지하여 휘발성 유기물질 제거 4.실내 공기 정화를 위해 공기 청정기 사용이나 베란다에 식물 배치\n",
      "\n",
      "소화기 종류는 ABC 소화기, 분말 소화기, 이산화탄소 소화기, 물 소화기, 거품 소화기, 블루젤 소화기, 화학방지복용 소화기가 있습니다.\n",
      "적절한 소화기를 선택할 때 화재 유형과 사용 용도를 고려하세요.\n",
      "Cosine Similarity Score :  0.6382187\n",
      "--------------------\n",
      "예측 :   석고보드를 이동할 때, 도배지 꼬임이 발생할 가능성이 있습니다. 이는 도배지의 종류에 따라 다르지만, 일반적으로 석고보드를 이동할 때 도배지가 꼬일 수 있습니다. 도배지 꼬임은 도배지의 신축성에 의해 발생하는데, 도배지가 꼬임이 발생하면 도배지의 신축성이 감소하여 도배지가 부풀어 오르거나 당겨질 수 있습니다. 따라서, 석고보드를 이동할 때에는 도배지의 신축성을 고려하여 적절한 이동 방법을 선택해야 합니다.\n",
      "정답 :  석고보드를 이동하면 도배지 꼬임이 발생할 수 있습니다. 꼬임은 석고보드의 이동으로 인한 부분으로, 해당 경우 하자 부분의 도배지를 제거한 후 퍼티와 샌딩 작업을 거친 뒤 재도배가 필요합니다. 전문가의 도움이 필요할 수 있습니다.\n",
      "\n",
      "건조시간이 충분하지 않으면 도배지 꼬임이 발생할 수 있습니다. 제조사의 권장 건조기간(보통 일주일) 동안 충분한 시간을 확보하고, 온도와 습도에 유의하여 관리해야 합니다. 꼬임이 계속되면 전문가의 도움을 받아야 합니다.\n",
      "Cosine Similarity Score :  0.7683252\n",
      "--------------------\n",
      "예측 :   상도작업은 도색작업을 하기 전에 벽면에 페인트를 칠하는 작업을 말합니다. 이 작업은 벽면의 상태와 색상에 따라 다양한 방법으로 진행됩니다. 벽면의 상태와 색상에 따라 적합한 페인트를 선택하고, 적절한 도색작업을 진행하는 것이 중요합니다. 또한, 공간을 넓어 보이게 하기 위해서는 밝고 화사한 색상을 선택하는 것이 좋습니다.\n",
      "정답 :  상도작업은 건축물의 외벽 또는 내부 공간에 방청도료가 완전히 건조된 후, 원하는 색상의 에나멜이나 조합페인트 등을 사용하여 마무리하는 작업입니다. 상도작업을 전문으로 하는 전문가에게 상담을 받는 것이 좋습니다.\n",
      "\n",
      "공간을 넓게 보이도록 하는 방법으로는 옅은 색상의 벽지와 세로 패턴, 길게 내려오는 커튼, 벽지와 조화된 가구 및 소품의 활용이 효과적입니다. 이를 통해 공간을 확장하는 느낌을 연출할 수 있습니다.\n",
      "Cosine Similarity Score :  0.67850316\n",
      "--------------------\n",
      "예측 :   대리석 타일은 난방 절감에 어떤 역할을 하나요? \n",
      "대리석 타일은 바닥에 열을 전달하는 것을 방지하는 데 도움을 줍니다. 이는 대리석 타일이 바닥과 접촉하여 열 전달을 차단하기 때문입니다. 또한, 대리석 타일은 바닥의 열이 대리석 타일에 전달되는 것을 방지하여 난방을 절감하는 데 도움을 줄 수 있습니다.\n",
      "정답 :  대리석 타일은 열전도율이 높아 난방비를 절감할 수 있으며, 독특한 문양과 색상으로 고급스러운 분위기를 연출합니다. 다만, 시공 난이도가 높고 평당 40~50만원의 고가이므로 전문가의 도움이 필요합니다. 또한, 깔끔한 느낌과 공간 확장 효과도 기대할 수 있습니다.\n",
      "Cosine Similarity Score :  0.65377665\n",
      "--------------------\n",
      "예측 :   외단열 시공 시 외부 환경 조건이 중요한 이유는 외단열 시공의 품질을 결정하는 요소 중 하나이기 때문입니다. 외단열 시공은 외부 환경 조건에 따라 시공 품질이 결정되며, 이는 시공자의 경험과 노하우에 크게 영향을 받습니다. 또한, 외단열 시공은 외부 환경 조건에 따라 시공 품질에 영향을 받을 수 있습니다. 외단열 시공의 품질을 높이기 위해서는 외부 환경 조건을 고려하여 시공 계획을 세우는 것이 중요합니다.\n",
      "정답 :  외단열은 건물의 겉면을 감싸주어 우수한 단열 효과를 제공하며, 열이 빠져나가거나 냉기가 들어오는 현상으로 인한 결로와 곰팡이 등의 하자 발생을 줄입니다. 그러나 외단열을 희망할 경우 외부 마감재가 필수이며, 외부에서의 작업은 날씨의 영향을 받기 때문에 숙련된 시공자의 작업이 중요합니다.\n",
      "Cosine Similarity Score :  0.75933385\n",
      "--------------------\n",
      "예측 :  공동주택의 실내 공기질을 측정하기 위한 가장 적절한 지점은 환기실입니다. 환기실에서는 실내 공기질을 측정하기 위해 주로 환기팬, 열교환기, 공기청정기 등의 기기를 사용합니다. 또한, 실내 공기질을 측정하기 위해 사용되는 기기는 공기질 측정기, 공기질 측정기, 공기질 측정기, 그리고 환기팬 등이 있습니다. 이 중에서 환기팬은 가장 보편적으로 사용되며, 환기실 내의 공기질을 측정하는 데 사용됩니다.\n",
      "정답 :  공동주택의 실내 공기질을 측정하기 위한 적절한 지점은 사무실 안에서 공기질이 가장 나쁠 것으로 예상되는 2곳 이상입니다. 측정은 사무실 바닥면으로부터 0.9미터 이상 1.5미터 이하의 높이에서 이루어져야 하며, 면적이 500제곱미터를 초과하는 경우 500제곱미터마다 1곳 추가로 측정해야 합니다.\n",
      "\n",
      "마감재의 하자를 판단하기 위한 방법은 설계도서와의 일치 여부, 기능상의 문제 여부, 미관상의 문제 여부, 안전상의 문제 여부를 확인하는 것입니다. 설계도서와의 일치 여부, 기능상 문제, 미관적 문제, 안전 문제를 종합적으로 고려하여 판단합니다.\n",
      "Cosine Similarity Score :  0.6743529\n",
      "--------------------\n",
      "예측 :  제진구조는 건물의 지진을 견딜 수 있도록 설계된 구조를 말합니다. 이 구조는 건물의 지진에 대한 내구성을 보장하며, 지진 발생 시 건물이 안정적으로 버틸 수 있도록 설계되어 있습니다. 중목구조 방식은 건물의 구조를 보다 견고하게 만들어 지진에 대한 내구성을 보장하는 방식입니다. 이 방식은 지진에 대한 내구성을 보장하기 위해 건물의 구조를 보다 견고하게 만들고, 지진 발생 시 건물이 안정적으로 버틸 수 있도록 설계된 방식입니다.\n",
      "정답 :  제진구조는 지진이 발생할 때 건물에 작용하는 지진 에너지를 최소화하여 건물의 안전성을 높이고 피해를 줄이는 역할을 합니다.\n",
      "\n",
      "중목구조는 건물을 지탱하기 위해 중앙에 큰 기둥을 두고 주변에 보를 배열하여 안정성을 제공하는 구조 방식으로, 전통적으로 동양 건축에서 사용된 방식 중 하나입니다.\n",
      "Cosine Similarity Score :  0.7957733\n",
      "--------------------\n",
      "예측 :   부드러운 욕실 인테리어를 위해 사용할 수 있는 소재로는 부드러운 질감을 가진 타일, 부드러운 텍스처를 가진 벽지, 그리고 부드러운 목재 등이 있습니다. 또한, 부드러운 질감을 가진 가구와 함께 부드러운 색상의 가구를 배치하는 것도 부드러운 욕실 인테리어를 완성하는 데 도움이 됩니다.\n",
      "정답 :  부드러운 욕실 인테리어를 위해는 연한 톤의 색상과 부드러운 소재를 활용할 수 있습니다. 예를 들어, 연한 베이지, 연한 그레이, 민트 그린과 같은 색상이나 대리석, 유리, 나무와 같은 소재가 적합합니다.\n",
      "\n",
      "반려동물을 위한 바닥재로는 방수 및 내구성이 뛰어난 비닐 프라이머리 바닥재나 타일, 또는 실리콘 바닥재 등이 사용될 수 있습니다. 이러한 소재는 청소가 쉽고, 반려동물의 발에 부드럽고 안전한 표면을 제공합니다.\n",
      "Cosine Similarity Score :  0.684268\n",
      "--------------------\n",
      "예측 :  팬던트 라이트는 천장에 부착하여 조명을 연출하는 라이트로, 주로 간접 조명에 사용됩니다. 이 라이트는 천장에 부착되어 있기 때문에 천장의 높이에 따라 다양한 분위기를 연출할 수 있습니다. 또한, 팬던트 라이트는 공간을 밝게 비추는 효과가 있어 간접 조명의 장점을 보완할 수 있습니다.\n",
      "정답 :  팬던트 라이트는 천장에 늘어뜨린 전선에 전구를 부착한 조명으로, 다양한 디자인과 소재로 제공되어 분위기를 연출하는 데 사용됩니다. 그러나 청소와 전구 교체가 어려운 단점이 있습니다.\n",
      "\n",
      "바닥재를 선택할 때는 사용 공간의 특성, 가구와의 조화, 편리한 청소 및 유지보수 등을 종합적으로 고려하여 적절한 소재를 선택해야 합니다.\n",
      "Cosine Similarity Score :  0.7508999\n",
      "--------------------\n",
      "예측 :  유성 발수제는 건물의 수명을 연장시키는 데에 큰 역할을 합니다. 이 발수제는 건물의 표면을 보호하고 부식을 방지하며, 내구성을 높이는 데에 사용됩니다. 이 발수제는 일반적으로 유기용제를 사용하며, 유기용제는 건물 내부에 스며들지 않도록 보호하는 역할을 합니다. 이러한 발수제는 건물 내부의 습기와 공기 중의 유해물질을 제거하여 건물의 수명을 연장시키는 데에 큰 역할을 합니다.\n",
      "정답 :  속건형 유성 발수제는 도장 후 용제가 증발하여 발수 효과를 발휘하는 유성계 발수제로, 표면에 발라지면 용제가 증발하여 수분이 떨어지게 되어 물을 효과적으로 방지합니다. 이 원리로 인해 건물의 외벽이나 다양한 재료에 사용되어 수분으로부터 보호되며, 이는 건물의 내구성을 높여 수명을 연장시키는 역할을 합니다.\n",
      "Cosine Similarity Score :  0.7525205\n",
      "--------------------\n",
      "예측 :   주방에서 조리할 때는 밝은 빛이 가장 적합합니다. 밝은 빛은 조리하는 데 있어서 효율적이며, 음식에 집중할 수 있도록 도와줍니다. 또한, 밝은 빛은 조리 중에 식재료가 눈에 띄지 않도록 도와주는 역할도 합니다. 따라서 밝은 조명을 사용하는 것이 주방에서 조리하는 데 있어서 가장 적합한 조명입니다.\n",
      "정답 :  주방에서는 식탁과 조리대에 따라 다른 조명이 적합합니다. 식탁 위에는 팬던트 조명을 설치하여 식사하는 사람들 간의 집중도를 높일 수 있습니다. 반면에 조리대는 밝은 LED 조명이 필요하며, 눈에 피로가 없을 정도로 밝게 조명되어야 합니다. 조리 공간은 200lux를 기준으로 150~300lux, 식탁은 100lux를 기준으로 60~150lux가 적절한 조도입니다.\n",
      "Cosine Similarity Score :  0.7705269\n",
      "--------------------\n",
      "예측 :   공명형 흡음재는 특정 주파수에 한정적으로 적용됩니다. 이는 흡음재의 재료에 따라 공명 주파수가 다르기 때문입니다. 흡음재는 재료에 따라 고유한 공명 주파수를 가지며, 이에 따라 공명형 흡음재의 재료에 따라 고유한 공명 주파수가 결정됩니다. 따라서, 공명형 흡음재는 특정 주파수에만 적용되며, 다른 주파수에서는 공명하지 않을 수 있습니다.\n",
      "정답 :  공명형 흡음재는 작은 구멍이나 틈의 공명을 활용하여 소리를 흡수하는데, 이는 주로 석면 시멘트판, 석고보드, 알루미늄판, 연질 섬유판, 합성수지판 등의 재료에서 이루어집니다. 이 소재들은 구멍 내부로 들어간 소리가 공진에 의해 소멸되는 특성이 있어 특정 주파수에 한정적으로 적용됩니다. 이를 통해 원하는 주파수대에서의 소리 흡수와 특정 주파수의 소리 향상이 가능합니다.\n",
      "Cosine Similarity Score :  0.7914391\n",
      "--------------------\n",
      "예측 :   결로는 실내와 실외의 온도 차이가 발생하여 실내에 이슬이 맺히는 현상을 의미합니다. 결로가 발생하는 원인은 실내와 실외의 온도 차이, 실내의 습도, 실내의 환기 등이 있습니다. 결로를 방지하기 위해서는 실내와 실외의 온도 차이를 최소화하고, 실내 습도를 50% 이하로 유지하는 것이 좋습니다. 또한, 환기를 통해 실내의 습도를 조절하고, 실내의 온도를 조절하여 결로를 예방할 수 있습니다.\n",
      "정답 :  결로가 발생하는 원인은 대기 중 습도가 높고 표면 온도가 낮은 조건입니다. 따라서 건물 내외의 습도 및 온도를 관리하고, 외부와 내부의 온도차를 줄이는 것이 중요합니다.\n",
      "Cosine Similarity Score :  0.5101236\n",
      "--------------------\n",
      "예측 :   강화마루는 주로 나무판재를 사용하여 제작됩니다. 강화마루는 일반 마루와는 다르게 특수한 열처리를 통해 제작됩니다. 이러한 열처리 과정에서는 나무판재를 특수한 열처리를 통해 경화시키는 과정이 필요합니다. 이 과정에서 강화마루가 제작됩니다. 강화마루는 일반 마루에 비해 높은 내구성과 내열성을 가지고 있어, 오랜 기간 동안 사용할 수 있습니다. 그러나 강화마루는 일반 마루에 비해 가격이 높고, 유지 보수가 어렵다는 단점이 있습니다.\n",
      "정답 :  강화마루는 원목 무늬 필름지를 입힌 하드코팅 처리된 바닥재로, 일반적으로 평당 7~12 만원의 가격대를 가지고 있습니다. 온도나 습도에 의한 변색이 거의 없고 강도가 뛰어나 수명이 긴 장점이 있습니다. 다만, 필름지 코팅으로 인해 질감과 보행감이 떨어지는 단점이 있습니다.\n",
      "\n",
      "징크판넬의 단점은 수명이 짧고, 부주의한 시공으로 인해 녹이 쉽게 발생할 수 있으며, 정기적인 유지보수가 필요하다는 점입니다.\n",
      "Cosine Similarity Score :  0.71393013\n",
      "--------------------\n",
      "예측 :   마감재의 하자를 판단하는 방법은 다양합니다. 먼저, 마감재의 표면이 평활하지 않거나 울퉁불퉁한 경우, 마감재의 표면이 평활하지 않거나 울퉁불퉁한 경우, 마감재의 표면이 심하게 변형되었거나 손상된 경우, 마감재의 표면이 불규칙하거나 평활하지 않은 경우 등을 확인할 수 있습니다. 이러한 경우에는 마감재를 교체하거나 보수해야 합니다. \n",
      "\n",
      "또한, 라돈을 측정하는 가장 적합한 지점은 건물 내부의 라돈 배출량을 측정하는 것입니다. 건물 내부의 라돈 배출량을 측정하기 위해서는 건물 내부의 공기질을 측정하는 공기질 측정기를 사용하거나, 건물 내부의 공기질을 측정하는 공기질 측정기를 사용할 수 있습니다. 이러한 장비는 건물 내부의 공기질을 측정하여 건물 내부의 공기질이 안전한지를 판단하는 데 도움을 줄 수 있습니다.\n",
      "정답 :  마감재의 하자를 판단하기 위해서는 설계도서와의 일치 여부, 기능상 문제, 미관상 문제, 안전상 문제 등을 고려해야 합니다.\n",
      "\n",
      "공동주택의 실내 라돈은 최저층에서 측정하며 공동주택의 총 세대수가 100세대일 때 3세대를 측정하고 이후 100세대가 증가할 때마다 1세대씩 추가하며 최대 12세대까지 시료를 채취합니다.\n",
      "Cosine Similarity Score :  0.27721852\n",
      "--------------------\n",
      "예측 :  중목구조 방식은 목재, 철근, 콘크리트 등을 사용하여 건물을 지을 때 사용하는 구조 방식입니다. 이 방식은 목재를 사용하여 건물의 구조를 지을 때, 목재의 특성을 활용하여 건물의 안정성을 높이는 장점이 있습니다. 또한, 목재의 자연스러운 느낌과 함께 건물의 내구성을 높일 수 있습니다.\n",
      "정답 :  중목구조는 건축물을 지탱하기 위해 중앙에 큰 기둥을 설치하고 주변에 보를 배열하는 구조 방식입니다. \n",
      "철근콘크리트 구조는 콘크리트의 압축 강도와 철근의 인장 강도를 결합하여 구성된 구조로, 일반적으로 도심에서 많이 사용됩니다.\n",
      "Cosine Similarity Score :  0.5699752\n",
      "--------------------\n",
      "예측 :   내진설계에서 안정성을 높이기 위한 순서는 다음과 같습니다. 먼저, 지진에 대한 내구성을 고려해야 합니다. 지진에 견딜 수 있는 구조를 설계하고, 지진 발생 시 건물이 안정적으로 버틸 수 있도록 설계합니다. 지진에 대비한 내진설계를 위해서는 지진에 견딜 수 있는 구조를 설계하고, 지진 발생 시 건물이 안정적으로 버틸 수 있도록 설계합니다. 또한, 지진 발생 시 건물의 안전성을 고려하여 설계합니다. 지진에 대비한 내진설계는 건물의 안전성을 높이기 위해 설계되며, 지진 발생 시 건물이 안정적으로 버틸 수 있도록 설계됩니다.\n",
      "정답 :  내진설계에서 안정성을 높이기 위한 순서는 내진구조, 제진구조, 면진구조 순입니다. \n",
      "\n",
      "내진구조는 지진으로부터 건물을 분산시켜 안정성을 높이는데 사용되며, 이는 강한 지진파에도 건축물이 붕괴되지 않도록 설계된 구조체입니다.\n",
      "Cosine Similarity Score :  0.7857691\n",
      "--------------------\n",
      "예측 :   평지붕의 누수 문제를 방지하기 위해서는 수성 벽체용 탄성 방수 도료를 사용하는 것이 좋습니다. 이 도료는 평지붕의 표면을 보호하고, 부식을 방지하며, 방수 기능을 제공하여 지붕의 수명을 연장시키는 데 도움이 됩니다.\n",
      "정답 :  수성 벽체용 탄성 방수 도료를 사용하는 장점은 다음과 같습니다:\n",
      "1. 우수한 방수성능 제공\n",
      "2. 크랙 방지와 물세척 가능\n",
      "3. 다양한 내외부 콘크리트 시멘트 구조물에 활용 가능\n",
      "4. 환경 친화적이고 낮은 냄새, 쉬운 청소 가능\n",
      "Cosine Similarity Score :  0.46720096\n",
      "--------------------\n",
      "전체 샘플의 Cosine Similarity Score 평균 :  0.62964875\n"
     ]
    }
   ],
   "source": [
    "preds = test_data_2['답변']\n",
    "gts = test_data_2['GPT 답변']\n",
    "\n",
    "sample_scores = []\n",
    "pred_embed_lst = []\n",
    "for pred, gt in zip(preds, gts):\n",
    "    # 생성된 답변 내용을 512 Embedding Vector로 변환\n",
    "    pred_embed = model.encode(pred)\n",
    "    gt_embed = model.encode(gt)\n",
    "    pred_embed_lst.append(pred_embed)\n",
    "\n",
    "    sample_score = cosine_similarity(gt_embed, pred_embed)\n",
    "    # Cosine Similarity Score가 0보다 작으면 0으로 간주\n",
    "    sample_score = max(sample_score, 0)\n",
    "    print('예측 : ', pred)\n",
    "    print('정답 : ', gt)\n",
    "    print('Cosine Similarity Score : ', sample_score)\n",
    "    print('-'*20)\n",
    "    sample_scores.append(sample_score)\n",
    "print('전체 샘플의 Cosine Similarity Score 평균 : ', np.mean(sample_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2['cosine_score'] = sample_scores\n",
    "test_data_2.to_csv(\"answer_sample.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.15606539125571628,\n",
       "  'p': 0.15967271534654362,\n",
       "  'f': 0.1527007706895985},\n",
       " 'rouge-2': {'r': 0.05553316314753993,\n",
       "  'p': 0.05010326928506194,\n",
       "  'f': 0.04998318327373176},\n",
       " 'rouge-l': {'r': 0.15425784207974608,\n",
       "  'p': 0.15786317610384928,\n",
       "  'f': 0.15090019450521952}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "rouge.get_scores(preds, gts, avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"sample_submission.csv\")\n",
    "preds = test_data['답변']\n",
    "pred_emds = model.encode(preds)\n",
    "sub_df.iloc[:,1:] = pred_emds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime(\"%m%d\")\n",
    "memo = 'base'\n",
    "new_model = f'KoAlpaca_{today}_{memo}'\n",
    "sub_df.to_csv(f\"submission_{new_model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ㅌ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
